<html lang="en" ng-app="hierarchie">
  <head>
  <title>Project: A quick glance into 775 thousand Kiva borrower stories</title>
  <!--script src="http://d3js.org/d3.v3.min.js" charset="utf-8"></script-->
  <script src="http://d3js.org/d3.v3.js" charset="utf-8"></script>

  <!-- Next elements added from Hierarchie-->
  <meta name="viewport" content="initial-scale=1.0, maximum-scale=1.0, user-scalable=0" />
  <link rel="stylesheet" type="text/css" media="all" href="app/css/app.css" />
  <link href='http://fonts.googleapis.com/css?family=Josefin+Slab:100,400' rel='stylesheet' type='text/css'>
  <link href='http://fonts.googleapis.com/css?family=Lato' rel='stylesheet' type='text/css'>
  </head>

  <body>
    
    <p>A few weeks ago, I made a microloan to political management student Yaqout from Al Hashmiya, Jordan.
      Twenty-three other lenders from around the globe did
      the same, reaching a total of $725. Yaqout will use the money to
      finance her next semester.</p>

    <p><img src="/images/yakout_from_jordan.jpg"/></p>

    <p>The loan was facilitated by <a href="http://www.kiva.org/" target="_blank">Kiva</a>, a microfinance
      platform that has been around since 2005. In ten years, hundreds
      of thousands of borrowers like Yaqout have supported their loan
      application with a <a href="http://www.kiva.org/lend/844974"
      target="_blank">personal story</a> describing their ambitions and plans.</p>

      <p>Over the years, Kiva have
      meticulously collected all these stories. What's more, they
      made them <a href="http://build.kiva.org/" target="_blank">available for further application development and
      research</a>. Perfect for a data science project!</p>

    <h2>Topic modelling as a subgoal of natural language processing</h2>

    <p>Over the past 2 1/2 weeks, the Metis Data Science Bootcamp
      introduced <a href="http://en.wikipedia.org/wiki/Natural_language_processing">Natural Language Processing</a>
      (= NLP, not to be confused with
      <a href="http://en.wikipedia.org/wiki/Neuro-linguistic_programming"
      target="_blank">Neuro-Linguistic Programming</a>). One subgoal
      of NLP is to make it easier for humans to process and interpret huge amounts of
      text data.</p>

    <p>While most earthlings nowadays
      routinely use <a href="http://google.com/" target="_blank">text search</a> (a.k.a. information retrieval),
      fewer are accustomed to getting (at least an impressionistic) insight into the contents of massive data collections.
      Yet, over the last 20 years,
      technologies like <a href="http://en.wikipedia.org/wiki/Latent_semantic_indexing">latent semantic indexing</a> and
      more recently <a href="http://www.cs.princeton.edu/~blei/papers/Blei2012.pdf" target="_blank">probabilistic topic
	models</a> have been developed to precisely address this need.</p>

    <h2>Kiva borrower stories at a glance</h2>

    <p>With the help
    of <a href="https://radimrehurek.com/gensim/" target="_blank">gensim</a>, an excellent Python library for topic modelling,
    we extracted 64 topics from a corpus containing 775 thousand
    borrower stories. Please refer to
    our <a href="http://nbviewer.ipython.org/github/fdurant/kiva_project/blob/master/hierarchical_topic_modelling_of_kiva_loan_descriptions.ipynb"
    target="_">iPython notebook</a>
    and <a href="https://github.com/fdurant/kiva_project"
    target="_">GitHub repository</a> for details.</p>
    
    <p>The end result of the topic modelling process is a topic
      hierarchy. To visualize it, we used
      the <a href="http://mlvl.github.io/Hierarchie/#/about">Hierarchie</a> 
      system developed at/by the <a href="http://www.dac.us/">Decisive Analytics Corporation</a>.</p>

    <p>The <a href="http://bl.ocks.org/mbostock/4348373">zoomable
    sunburst</a> graph below offers a bird's-eye view of the Kiva borrower stories. Each of the 64 outer segments 
    represents one core topic, which is expressed as a probability distribution over a vocabulary of 1000 words (excluding stop
      words and other very frequent words). From these
      1000 words, only the <em>seven</em> most prominent ones are shown for each topic.
      The inner segments represent successive higher-abstract groupings of the core topics.</p>

    <p>The breadcrumb arrow at the top left-hand side shows the path of all most prominent words visited, as you traverse
      the hierarchy from the central circle to the outer rings, and back.</p>

    <div ng-view>
      <script src="bower_components/d3/d3.min.js"></script>
      <script src="bower_components/angular/angular.js"></script>
      <script src="bower_components/angular-route/angular-route.js"></script>
      <script src="bower_components/underscore/underscore.js"></script>
      <script src="app/js/app.js"></script>
      <script src="app/js/routes.js"></script>
      <script src="app/js/services.js"></script>
      <script src="app/js/controllers.js"></script>
      <script src="app/js/filters.js"></script>
      <script src="app/js/directives.js"></script>		
      <script src="app/js/directives/breadcrumb.js"></script>
      <script src="app/js/directives/sunburst-perspective.js"></script>
      <script src="app/js/directives/sunburst.js"></script>  
    </div>

    <p align="right"><small>See <a href="http://mlvl.github.io/Hierarchie/#/about">Hierarchie intro</a></small></p>

    <p>The size of each segment represents the presence of this topic in the whole collection, i.e. across
      <em>all</em> borrower stories. In probabilistic topic modelling, each document is indeed seen as having
      been generated by a probabilistic draw from <em>all</em> topics in the data collection - with some
      topics being more prominent than others. Otherwise stated:
      no single document has an <em>exclusive</em> relationship to a
      single topic, and vice versa.</p>

    <p>The colors have no other purpose than to serve visual
    distinctiveness; they do not carry any meaning as such.</p>

    </body>

</html>
